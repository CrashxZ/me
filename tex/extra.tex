\begin{center}
    \Large{\textbf{ByteBoost Cybertraining Program: Research Statement}}\\

\end{center}

I am a Ph.D. student at the University of Connecticut specializing in autonomous robotics and intelligent scheduling for wireless-powered communication networks, my research focuses on developing resource-efficient artificial intelligence solutions for real-world robotic environments and IoT systems. My work combines technologies like reinforcement learning, embedded systems, and high-performance computing. Recently, my research focuses on training low-parameter Large Language Models (LLMs) to help optimize scheduling and decision-making for dynamic, resource-constrained environments.

\textbf{Motivation to Participate in ByteBoost}

The rapid advancement of computational hardware—especially accelerators like NVIDIA and Intel GPUs, Cerebras CS-2, and ARM-based processors—has transformed the landscape of AI research. However, access to, and hands-on experience with, such cutting-edge testbeds remain limited for many researchers. My motivation to participate in ByteBoost stems from a desire to bridge this gap:
\begin{itemize}
    \item \textbf{Benchmarking and optimization:} I aim to explore how low-parameter LLMs and reinforcement learning agents can be efficiently trained and deployed on novel architectures such as those available on ACES, Neocortex, and Ookami.
    \item \textbf{Scalability and portability:} Understanding performance trade-offs and best practices for porting models across diverse hardware platforms is essential to ensure my research outcomes are robust, scalable, and impactful.
\end{itemize}

\textbf{Relevant Experience and Research Applications}

I believe that my research and technical background uniquely positions me to benefit from the ByteBoost program:
\begin{itemize}
    \item \textbf{Model Training and Optimization:} I have prior experience training reinforcement learning models and LLMs on UConn’s High Performance Computing (HPC) cluster, leveraging NVIDIA A100 GPUs and Slurm for distributed training and large-scale experimentation.
    \begin{itemize}
        \item \textit{PEFT (Parameter-Efficient Fine-Tuning):} Implementing and benchmarking LoRA (Low-Rank Adaptation) and related techniques to fine-tune large models efficiently on limited computational resources.
        \item \textit{Quantization:} Applying post-training quantization methods to reduce model size and accelerate inference, especially for deployment on resource-constrained platforms (e.g., ARM-based SBCs, embedded systems).
        \item \textit{Prompt Engineering:} Developing, testing, and benchmarking both zero-shot and n-shot prompt strategies to optimize LLM performance on real-world scheduling and decision-making tasks in robotics and IoT environments.
    \end{itemize}
    \item \textbf{Research Focus:} My work on charge scheduling agents and mobile charger coordination in wireless sensor networks combines deep RL and efficient LLMs, with an emphasis on scalability and adaptability across heterogeneous computing environments.
    \item \textbf{Portability and Profiling:} I have experience porting, profiling, and optimizing AI models for a wide range of architectures, addressing real challenges in deploying advanced AI solutions to both edge and high-performance platforms.
\end{itemize}

\textbf{Objectives for ByteBoost}

Through the ByteBoost Cybertraining Program, I hope to:
\begin{itemize}
    \item Gain practical experience with the latest composable accelerator hardware, ARM-based SIMD-vector processors, and the Cerebras wafer-scale platform.
    \item Use Byteboost's resources to optimize my PEFT/LoRA-trained LLMs and RL agents across these testbeds, identifying hardware-specific bottlenecks and optimization opportunities.
    \item Sharpen my ability to migrate and scale AI workflows across heterogeneous computing environments.
    \item Engage with a community of researchers and build relevant connections for future career prospects.
\end{itemize}

\textbf{Broader Impact}

Participation in ByteBoost will directly benefit my dissertation work and enable me to bring state-of-the-art computational practices back to my lab at UConn. I am committed to sharing the insights and skills gained with fellow researchers and students—both by integrating new methodologies into our robotics/AI curriculum and through collaborative projects. My goal is to help advance the accessibility, efficiency, and scalability of AI-driven decision-making in robotics and IoT, contributing to a broader, community-driven impact.

